{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ebcf3ce-5a9f-4ebf-b8d9-5f5af80e25e8",
   "metadata": {},
   "source": [
    "In this notebook, you will:\n",
    "\n",
    "- Create a SageMaker model from a trained model artifact\n",
    "- Configure and deploy a real-time inference endpoint to serve the model\n",
    "- Invoke the endpoint to run sample predictions using test data\n",
    "- Attach an autoscaling policy to the endpoint to handle traffic changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f57f57-5330-4592-8f2a-bebd949b2cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade -q sagemaker aiobotocore boto3 botocore awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88858f02-d807-4269-a959-bb9484d9d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "from io import StringIO\n",
    "import base64\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "sm_autoscaling_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "# S3 locations used for parameterizing the notebook run\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\" \n",
    "model_prefix = \"models/xgb-fraud\"\n",
    "\n",
    "data_capture_key = f\"{write_prefix}/data-capture\"\n",
    "\n",
    "# S3 location of trained model artifact\n",
    "model_uri = f\"s3://{read_bucket}/{model_prefix}/fraud-det-xgb-model.tar.gz\"\n",
    "\n",
    "# S3 path where data captured at endpoint will be stored\n",
    "data_capture_uri = f\"s3://{write_bucket}/{data_capture_key}\"\n",
    "\n",
    "# S3 location of test data\n",
    "test_data_uri = f\"s3://{read_bucket}/{read_prefix}/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1c3f65-b06c-47c4-b1ad-10a878528f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the SageMaker managed XGBoost image\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "\n",
    "# Specify a unique model name that does not exist\n",
    "model_name = \"fraud-detect-xgb\"\n",
    "primary_container = {\n",
    "                     \"Image\": training_image,\n",
    "                     \"ModelDataUrl\": model_uri\n",
    "                    }\n",
    "\n",
    "model_matches = sm_client.list_models(NameContains=model_name)[\"Models\"]\n",
    "if not model_matches:\n",
    "    model = sm_client.create_model(ModelName=model_name,\n",
    "                                   PrimaryContainer=primary_container,\n",
    "                                   ExecutionRoleArn=sagemaker_role)\n",
    "else:\n",
    "    print(f\"Model with name {model_name} already exists! Change model name to create new\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6cfbe3-3f2e-49c2-a330-9e0a63957228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint Config name\n",
    "endpoint_config_name = f\"{model_name}-endpoint-config\"\n",
    "\n",
    "# Endpoint config parameters\n",
    "production_variant_dict = {\n",
    "                           \"VariantName\": \"Alltraffic\",\n",
    "                           \"ModelName\": model_name,\n",
    "                           \"InitialInstanceCount\": 1,\n",
    "                           \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                           \"InitialVariantWeight\": 1\n",
    "                          }\n",
    "\n",
    "# Data capture config parameters\n",
    "data_capture_config_dict = {\n",
    "                            \"EnableCapture\": True,\n",
    "                            \"InitialSamplingPercentage\": 100,\n",
    "                            \"DestinationS3Uri\": data_capture_uri,\n",
    "                            \"CaptureOptions\": [{\"CaptureMode\" : \"Input\"}, {\"CaptureMode\" : \"Output\"}]\n",
    "                           }\n",
    "\n",
    "\n",
    "# Create endpoint config if one with the same name does not exist\n",
    "endpoint_config_matches = sm_client.list_endpoint_configs(NameContains=endpoint_config_name)[\"EndpointConfigs\"]\n",
    "if not endpoint_config_matches:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "                                                                EndpointConfigName=endpoint_config_name,\n",
    "                                                                ProductionVariants=[production_variant_dict],\n",
    "                                                                DataCaptureConfig=data_capture_config_dict\n",
    "                                                               )\n",
    "else:\n",
    "    print(f\"Endpoint config with name {endpoint_config_name} already exists! Change endpoint config name to create new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e777fd4-99dd-4052-9a82-09ee9a447557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Status: Creating...\n",
      "Endpoint Status: Creating...\n",
      "Endpoint Status: Creating...\n",
      "Endpoint Status: InService\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_matches = sm_client.list_endpoints(NameContains=endpoint_name)[\"Endpoints\"]\n",
    "if not endpoint_matches:\n",
    "    endpoint_response = sm_client.create_endpoint(\n",
    "                                                  EndpointName=endpoint_name,\n",
    "                                                  EndpointConfigName=endpoint_config_name\n",
    "                                                 )\n",
    "else:\n",
    "    print(f\"Endpoint with name {endpoint_name} already exists! Change endpoint name to create new\")\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "while status == \"Creating\":\n",
    "    print(f\"Endpoint Status: {status}...\")\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fd86a-4092-4b9f-9ce7-3b5ffc280fb9",
   "metadata": {},
   "source": [
    "# Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921425b6-d8f3-483d-b10a-51cc8fa91f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02243666537106037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02243666537106037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0799826979637146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.13931523263454437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03112351894378662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Prediction  Label\n",
       "0  0.02243666537106037      0\n",
       "1  0.02243666537106037      0\n",
       "2   0.0799826979637146      0\n",
       "3  0.13931523263454437      0\n",
       "4  0.03112351894378662      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch test data to run predictions with the endpoint\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "\n",
    "# For content type text/csv, payload should be a string with commas separating the values for each feature\n",
    "# This is the inference request serialization step\n",
    "# CSV serialization\n",
    "csv_file = io.StringIO()\n",
    "test_sample = test_df.drop([\"fraud\"], axis=1).iloc[:5]\n",
    "test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "payload = csv_file.getvalue()\n",
    "response = sm_runtime_client.invoke_endpoint(\n",
    "                                             EndpointName=endpoint_name,\n",
    "                                             Body=payload,\n",
    "                                             ContentType=\"text/csv\",\n",
    "                                             Accept=\"text/csv\"\n",
    "                                            )\n",
    "\n",
    "# This is the inference response deserialization step\n",
    "# This is a bytes object\n",
    "result = response[\"Body\"].read()\n",
    "# Decoding bytes to a string\n",
    "result = result.decode(\"utf-8\")\n",
    "# Converting to list of predictions\n",
    "result = re.split(\",|\\n\",result)\n",
    "\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df[\"Prediction\"] = result[:5]\n",
    "prediction_df[\"Label\"] = test_df[\"fraud\"].iloc[:5].values\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789151ea-d170-4c68-8158-096a06347d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for captures to show up..........................................................................................\n",
      "Found 17 Data Capture Files:\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(90):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "print()\n",
    "print(f\"Found {len(capture_files)} Data Capture Files:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3670f958-24d9-4ec7-b158-6da13185d34c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'captureData': {'endpointInput': {'observedContentType': 'text/csv',\n",
       "   'mode': 'INPUT',\n",
       "   'data': 'MiwwLDAsMSw1ODQwMCwxNDI0Ny43NjY4NjY2NzA4NSw3MjY0Ny43NjY4NjY2NzA4NSw3LDI5LDAsMTEsNDEsMTA4LDAsMSw3NTAsMzAwMCwwLDIsMjAxNCwwLDAsMSwwLDAsMSwwLDAsMCwxLDAsMCwwLDAsMSwwLDAsMSwwLDEsMCwwLDAsMCwwLDAsMCwxCjIsMCwyLDAsMTE1MDAsMTA2NzUuNjcxMzQ2NzM4MTU4LDIyMTc1LjY3MTM0NjczODE2LDExLDI4LDMsMTYsNTQsMTcxLDAsMSw3NTAsMjc1MCwyLDMsMjAxNSwwLDAsMCwwLDEsMSwwLDAsMCwxLDAsMCwwLDAsMSwwLDAsMSwwLDEsMCwwLDAsMCwwLDAsMCwxCjIsMCwwLDEsMTg1MDAsMTAyMDIuMjY2MzUzOTk5Nzc2LDI4NzAyLjI2NjM1Mzk5OTc3LDEsNiw2LDgsNTEsMTk2LDAsMSw3NTAsMzAwMCwwLDEsMjAxMSwwLDAsMCwwLDEsMSwwLDAsMSwwLDAsMCwwLDEsMCwwLDAsMSwwLDEsMCwwLDAsMCwwLDAsMSwwCjEsMCwwLDAsMTYzMDAsOTMzOC4zNDgwNjY0MzU3MTgsMjU2MzguMzQ4MDY2NDM1NzIsOSwxLDYsMyw1NywxMjIsMCwxLDc1MCwzMDAwLDEsMSwyMDE1LDAsMCwwLDEsMCwwLDEsMCwwLDAsMSwwLDAsMCwxLDAsMCwxLDAsMSwwLDAsMCwwLDAsMCwxLDAKMiwxLDAsMCwxNDcwMCwyODE0NS45MjQ5OTQxODIyNSw0Mjg0NS45MjQ5OTQxODIyNSwxMCwyMywyLDE1LDU5LDE0MiwwLDEsNzUwLDMwMDAsMiwzLDIwMTksMCwwLDEsMCwwLDEsMCwwLDEsMCwwLDAsMCwxLDAsMCwwLDAsMSwwLDAsMCwwLDAsMSwwLDEsMAo=',\n",
       "   'encoding': 'BASE64'},\n",
       "  'endpointOutput': {'observedContentType': 'text/csv; charset=utf-8',\n",
       "   'mode': 'OUTPUT',\n",
       "   'data': 'MC4wMjI0MzY2NjUzNzEwNjAzNwowLjAyMjQzNjY2NTM3MTA2MDM3CjAuMDc5OTgyNjk3OTYzNzE0NgowLjEzOTMxNTIzMjYzNDU0NDM3CjAuMDMxMTIzNTE4OTQzNzg2NjIK',\n",
       "   'encoding': 'BASE64'}},\n",
       " 'eventMetadata': {'eventId': '8e2fcce6-e60a-46d1-a3ed-ad8782a1882e',\n",
       "  'inferenceTime': '2023-04-12T07:17:51Z'},\n",
       " 'eventVersion': '0'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "capture_file = S3Downloader.read_file(capture_files[0]).split(\"\\n\")\n",
    "capture_record = json.loads(capture_file[0])\n",
    "capture_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e849bc80-4ca8-426e-a4db-ec4ff7278bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,0,0,1,58400,14247.76686667085,72647.76686667085,7,29,0,11,41,108,0,1,750,3000,0,2,2014,0,0,1,0,0,1,0,0,0,1,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,1', '2,0,2,0,11500,10675.671346738158,22175.67134673816,11,28,3,16,54,171,0,1,750,2750,2,3,2015,0,0,0,0,1,1,0,0,0,1,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,1', '2,0,0,1,18500,10202.266353999776,28702.26635399977,1,6,6,8,51,196,0,1,750,3000,0,1,2011,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,1,0', '1,0,0,0,16300,9338.348066435718,25638.34806643572,9,1,6,3,57,122,0,1,750,3000,1,1,2015,0,0,0,1,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,1,0', '2,1,0,0,14700,28145.92499418225,42845.92499418225,10,23,2,15,59,142,0,1,750,3000,2,3,2019,0,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,1,0', '']\n",
      "['0.02243666537106037', '0.02243666537106037', '0.0799826979637146', '0.13931523263454437', '0.03112351894378662', '']\n"
     ]
    }
   ],
   "source": [
    "input_data = capture_record[\"captureData\"][\"endpointInput\"][\"data\"]\n",
    "output_data = capture_record[\"captureData\"][\"endpointOutput\"][\"data\"]\n",
    "input_data_list = base64.b64decode(input_data).decode(\"utf-8\").split(\"\\n\")\n",
    "print(input_data_list)\n",
    "output_data_list = base64.b64decode(output_data).decode(\"utf-8\").split(\"\\n\")\n",
    "print(output_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993e223-e2ee-43a8-9780-8bce01c63921",
   "metadata": {},
   "source": [
    "# Auto scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f151d1ef-ec62-45ae-b18c-b76049c7b37e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# SageMaker expects resource id to be provided with the following structure\n",
    "resource_id = f\"endpoint/{endpoint_name}/variant/{resp['ProductionVariants'][0]['VariantName']}\"\n",
    "\n",
    "# Scaling configuration\n",
    "scaling_config_response = sm_autoscaling_client.register_scalable_target(\n",
    "                                                          ServiceNamespace=\"sagemaker\",\n",
    "                                                          ResourceId=resource_id,\n",
    "                                                          ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\", \n",
    "                                                          MinCapacity=1,\n",
    "                                                          MaxCapacity=2\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe231f87-e45a-4af3-9411-3a5e0954c28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Scaling Policy\n",
    "policy_name = f\"scaling-policy-{endpoint_name}\"\n",
    "scaling_policy_response = sm_autoscaling_client.put_scaling_policy(\n",
    "                                                PolicyName=policy_name,\n",
    "                                                ServiceNamespace=\"sagemaker\",\n",
    "                                                ResourceId=resource_id,\n",
    "                                                ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "                                                PolicyType=\"TargetTrackingScaling\",\n",
    "                                                TargetTrackingScalingPolicyConfiguration={\n",
    "                                                    \"TargetValue\": 5.0, # Target for avg invocations per minutes\n",
    "                                                    \"PredefinedMetricSpecification\": {\n",
    "                                                        \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\",\n",
    "                                                    },\n",
    "                                                    \"ScaleInCooldown\": 600, # Duration in seconds until scale in\n",
    "                                                    \"ScaleOutCooldown\": 60 # Duration in seconds between scale out\n",
    "                                                }\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c3b9a64-a072-4d5f-bb09-a0e6f36fc317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'scaling-policy-fraud-detect-xgb-endpoint'\n",
      "\n",
      "{   'PredefinedMetricSpecification': {   'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'},\n",
      "    'ScaleInCooldown': 600,\n",
      "    'ScaleOutCooldown': 60,\n",
      "    'TargetValue': 5.0}\n"
     ]
    }
   ],
   "source": [
    "response = sm_autoscaling_client.describe_scaling_policies(ServiceNamespace=\"sagemaker\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=4)\n",
    "for i in response[\"ScalingPolicies\"]:\n",
    "    pp.pprint(i[\"PolicyName\"])\n",
    "    print(\"\")\n",
    "    if(\"TargetTrackingScalingPolicyConfiguration\" in i):\n",
    "        pp.pprint(i[\"TargetTrackingScalingPolicyConfiguration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e68c431-5924-4f83-b410-58e986158cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint will be tested for 250 seconds\n"
     ]
    }
   ],
   "source": [
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Endpoint will be tested for {request_duration} seconds\")\n",
    "while time.time() < end_time:\n",
    "    csv_file = io.StringIO()\n",
    "    test_sample = test_df.drop([\"fraud\"], axis=1).iloc[[np.random.randint(0, test_df.shape[0])]]\n",
    "    test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "    payload = csv_file.getvalue()\n",
    "    response = sm_runtime_client.invoke_endpoint(\n",
    "                                                 EndpointName=endpoint_name,\n",
    "                                                 Body=payload,\n",
    "                                                 ContentType=\"text/csv\"\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acbdd411-8a70-4cc4-b605-d4ed3fb9fc70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Instance count increase for a max of 250 seconds. Please re run this cell in case the count does not change\n",
      "Status: InService\n",
      "Current Instance count: 1\n",
      "Status: InService\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: InService\n",
      "Current Instance count: 2\n"
     ]
    }
   ],
   "source": [
    "# Check the instance counts after the endpoint gets more load\n",
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = response[\"EndpointStatus\"]\n",
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Waiting for Instance count increase for a max of {request_duration} seconds. Please re run this cell in case the count does not change\")\n",
    "while time.time() < end_time:\n",
    "    response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = response[\"EndpointStatus\"]\n",
    "    instance_count = response[\"ProductionVariants\"][0][\"CurrentInstanceCount\"]\n",
    "    print(f\"Status: {endpoint_status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")\n",
    "    if (endpoint_status==\"InService\") and (instance_count>1):\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7d185-bf38-47dc-9cbc-2c3efedbdbe4",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a53ac53-3913-42cd-b8eb-223ab5432343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'e000bfb7-b2bb-4e4c-8647-d334d56f1adc',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e000bfb7-b2bb-4e4c-8647-d334d56f1adc',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 13 Apr 2023 11:42:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete model\n",
    "sm_client.delete_model(ModelName=model_name)\n",
    "\n",
    "# Delete endpoint configuration\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete endpoint\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
